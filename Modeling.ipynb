{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn as sk\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import export_graphviz\n",
    "import graphviz\n",
    "from graphviz import Graph\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import plotly.express as px\n",
    "from datetime import date \n",
    "from wrangle import new_city_data, clean_city, missing_zero_values_table, train_validate_test_split\n",
    "import explore\n",
    "\n",
    "from model import run_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = new_city_data()\n",
    "df = clean_city(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 11910 entries, 12 to 11923\n",
      "Data columns (total 21 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   annual_salary_2016         11910 non-null  float64\n",
      " 1   base_pay_2016              11910 non-null  float64\n",
      " 2   leave_payout_2016          11910 non-null  float64\n",
      " 3   other_2016                 11910 non-null  float64\n",
      " 4   overtime_2016              11910 non-null  float64\n",
      " 5   gross_earnings_2016        11910 non-null  float64\n",
      " 6   additional_compensation    11910 non-null  float64\n",
      " 7   total_compensation         11910 non-null  float64\n",
      " 8   department                 11910 non-null  object \n",
      " 9   gender                     11910 non-null  object \n",
      " 10  ethnicity                  11910 non-null  object \n",
      " 11  years_employed             11910 non-null  int64  \n",
      " 12  job_id                     11910 non-null  object \n",
      " 13  job_name                   11910 non-null  object \n",
      " 14  ethnicity_ASIAN            11910 non-null  uint8  \n",
      " 15  ethnicity_BLACK            11910 non-null  uint8  \n",
      " 16  ethnicity_HISPANIC         11910 non-null  uint8  \n",
      " 17  ethnicity_NATIVE AMERICAN  11910 non-null  uint8  \n",
      " 18  ethnicity_NATIVE HAWAIIAN  11910 non-null  uint8  \n",
      " 19  ethnicity_OTHER            11910 non-null  uint8  \n",
      " 20  ethnicity_WHITE            11910 non-null  uint8  \n",
      "dtypes: float64(8), int64(1), object(5), uint8(7)\n",
      "memory usage: 1.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, validate, test = train_validate_test_split(df, seed=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seperate out our X and y values\n",
    "X_train = train.drop(columns=['gender', 'department', 'ethnicity', 'job_name', 'job_id'])\n",
    "y_train = train.gender\n",
    "\n",
    "X_validate = validate.drop(columns=['gender', 'department', 'ethnicity', 'job_name', 'job_id'])\n",
    "y_validate = validate.gender\n",
    "\n",
    "X_test = test.drop(columns=['gender', 'department', 'ethnicity', 'job_name', 'job_id'])\n",
    "y_test = test.gender"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "<h3>Establish the Baseline</h3>\n",
    "\n",
    "------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MALE      4355\n",
       "FEMALE    2314\n",
       "Name: gender, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The most frequenly observed outcome will be our baseline\n",
    "\n",
    "train.gender.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our baseline accuracy is 65.0%\n"
     ]
    }
   ],
   "source": [
    "baseline_accuracy = (round((train.gender == 'MALE').mean(), 2)* 100)\n",
    "\n",
    "print(f'Our baseline accuracy is {baseline_accuracy}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------\n",
    "\n",
    "<h3>Logistic Regression Model</h3>\n",
    "\n",
    "--------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline is 65.0\n",
      "Accuracy of Logistic Regression classifier on training set: 0.70\n"
     ]
    }
   ],
   "source": [
    "# Create the logistic regression\n",
    "logit = LogisticRegression(random_state=123)\n",
    "\n",
    "# specify the features we're using\n",
    "features = ['annual_salary_2016','base_pay_2016', 'leave_payout_2016', 'other_2016', 'overtime_2016', 'additional_compensation', 'total_compensation',\n",
    "           'years_employed', 'ethnicity_ASIAN', 'ethnicity_BLACK', 'ethnicity_HISPANIC', 'ethnicity_NATIVE AMERICAN', 'ethnicity_NATIVE HAWAIIAN',\n",
    "           'ethnicity_OTHER', 'ethnicity_WHITE']\n",
    "# Fit a model using only these specified features\n",
    "# logit.fit(X_train[[\"age\", \"pclass\", \"fare\"]], y_train)\n",
    "logit.fit(X_train[features], y_train)\n",
    "\n",
    "# Since we .fit on a subset, we .predict on that same subset of features\n",
    "y_pred = logit.predict(X_train[features])\n",
    "\n",
    "print(\"Baseline is\", round(baseline_accuracy, 2))\n",
    "print('Accuracy of Logistic Regression classifier on training set: {:.2f}'\n",
    "     .format(logit.score(X_train[features], y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logit1 model using salary data, ethnicity, and years employed\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      FEMALE       0.58      0.45      0.51       992\n",
      "        MALE       0.74      0.83      0.78      1867\n",
      "\n",
      "    accuracy                           0.70      2859\n",
      "   macro avg       0.66      0.64      0.64      2859\n",
      "weighted avg       0.68      0.70      0.69      2859\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's determine logit1's metrics on validate\n",
    "features = ['annual_salary_2016','base_pay_2016', 'leave_payout_2016', 'other_2016', 'overtime_2016', 'additional_compensation', 'total_compensation',\n",
    "           'years_employed', 'ethnicity_ASIAN', 'ethnicity_BLACK', 'ethnicity_HISPANIC', 'ethnicity_NATIVE AMERICAN', 'ethnicity_NATIVE HAWAIIAN',\n",
    "           'ethnicity_OTHER', 'ethnicity_WHITE']\n",
    "y_pred = logit.predict(X_validate[features])\n",
    "\n",
    "print('Logit1 model using salary data, ethnicity, and years employed')\n",
    "print(classification_report(y_validate, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------\n",
    "\n",
    "<h3>KNN Model</h3>\n",
    "\n",
    "--------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's make the model\n",
    "knn = KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['annual_salary_2016','base_pay_2016', 'leave_payout_2016', 'other_2016', 'overtime_2016', 'additional_compensation', 'total_compensation',\n",
    "           'years_employed', 'ethnicity_ASIAN', 'ethnicity_BLACK', 'ethnicity_HISPANIC', 'ethnicity_NATIVE AMERICAN', 'ethnicity_NATIVE HAWAIIAN',\n",
    "           'ethnicity_OTHER', 'ethnicity_WHITE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.799\n"
     ]
    }
   ],
   "source": [
    "# Now let's train the model!\n",
    "knn.fit(X_train[features], y_train)\n",
    "\n",
    "# Let's check the accuracy\n",
    "accuracy = knn.score(X_train[features], y_train)\n",
    "print(f\"accuracy is {accuracy:.3}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "y_pred = knn.predict(X_train[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      FEMALE       0.72      0.69      0.70      2314\n",
      "        MALE       0.84      0.86      0.85      4355\n",
      "\n",
      "    accuracy                           0.80      6669\n",
      "   macro avg       0.78      0.77      0.78      6669\n",
      "weighted avg       0.80      0.80      0.80      6669\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's check our other classification metrics\n",
    "# y_train is the actual labels for the target variable\n",
    "# y_pred is the predictions that the model makes based off our X features\n",
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.799\n"
     ]
    }
   ],
   "source": [
    "# Let's check the accuracy\n",
    "accuracy = knn.score(X_train[features], y_train)\n",
    "print(f\"accuracy is {accuracy:.3}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "features = ['annual_salary_2016','base_pay_2016', 'leave_payout_2016', 'other_2016', 'overtime_2016', 'additional_compensation', 'total_compensation',\n",
    "           'years_employed', 'ethnicity_ASIAN', 'ethnicity_BLACK', 'ethnicity_HISPANIC', 'ethnicity_NATIVE AMERICAN', 'ethnicity_NATIVE HAWAIIAN',\n",
    "           'ethnicity_OTHER', 'ethnicity_WHITE']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------\n",
    "\n",
    "<h3>Random Forest</h3>\n",
    "\n",
    "--------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['annual_salary_2016','base_pay_2016', 'leave_payout_2016', 'other_2016', 'overtime_2016', 'additional_compensation', 'total_compensation',\n",
    "           'years_employed', 'ethnicity_ASIAN', 'ethnicity_BLACK', 'ethnicity_HISPANIC', 'ethnicity_NATIVE AMERICAN', 'ethnicity_NATIVE HAWAIIAN',\n",
    "           'ethnicity_OTHER', 'ethnicity_WHITE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics_binary(rf):\n",
    "    '''\n",
    "    get_metrics_binary takes in a confusion matrix (cnf) for a binary classifier and prints out metrics based on\n",
    "    values in variables named X_train, y_train, and y_pred.\n",
    "    \n",
    "    return: a classification report as a transposed DataFrame\n",
    "    '''\n",
    "    accuracy = rf.score(X_train[features], y_train)\n",
    "    class_report = pd.DataFrame(classification_report(y_train, y_pred, output_dict=True)).T\n",
    "    conf = confusion_matrix(y_train, y_pred)\n",
    "    tpr = conf[1][1] / conf[1].sum()\n",
    "    fpr = conf[0][1] / conf[0].sum()\n",
    "    tnr = conf[0][0] / conf[0].sum()\n",
    "    fnr = conf[1][0] / conf[1].sum()\n",
    "    print(f'''\n",
    "    The accuracy for our model is {accuracy:.4}\n",
    "    The True Positive Rate is {tpr:.3}, The False Positive Rate is {fpr:.3},\n",
    "    The True Negative Rate is {tnr:.3}, and the False Negative Rate is {fnr:.3}\n",
    "    ''')\n",
    "    return class_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the Random Forest Model\n",
    "rf = RandomForestClassifier(bootstrap=True, \n",
    "                            class_weight=None, \n",
    "                            criterion='gini',\n",
    "                            min_samples_leaf=1,\n",
    "                            n_estimators=100,\n",
    "                            max_depth=10, \n",
    "                            random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=10, random_state=123)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.fit(X_train[features], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rf.predict(X_train[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba = rf.predict_proba(X_train[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    The accuracy for our model is 0.8481\n",
      "    The True Positive Rate is 0.879, The False Positive Rate is 0.21,\n",
      "    The True Negative Rate is 0.79, and the False Negative Rate is 0.121\n",
      "    \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>FEMALE</th>\n",
       "      <td>0.776456</td>\n",
       "      <td>0.789542</td>\n",
       "      <td>0.782944</td>\n",
       "      <td>2314.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MALE</th>\n",
       "      <td>0.887164</td>\n",
       "      <td>0.879219</td>\n",
       "      <td>0.883174</td>\n",
       "      <td>4355.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.848103</td>\n",
       "      <td>0.848103</td>\n",
       "      <td>0.848103</td>\n",
       "      <td>0.848103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.831810</td>\n",
       "      <td>0.834381</td>\n",
       "      <td>0.833059</td>\n",
       "      <td>6669.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.848751</td>\n",
       "      <td>0.848103</td>\n",
       "      <td>0.848396</td>\n",
       "      <td>6669.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score      support\n",
       "FEMALE         0.776456  0.789542  0.782944  2314.000000\n",
       "MALE           0.887164  0.879219  0.883174  4355.000000\n",
       "accuracy       0.848103  0.848103  0.848103     0.848103\n",
       "macro avg      0.831810  0.834381  0.833059  6669.000000\n",
       "weighted avg   0.848751  0.848103  0.848396  6669.000000"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_report = get_metrics_binary(rf)\n",
    "class_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.75\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      FEMALE       0.64      0.61      0.62       992\n",
      "        MALE       0.80      0.82      0.81      1867\n",
      "\n",
      "    accuracy                           0.75      2859\n",
      "   macro avg       0.72      0.71      0.72      2859\n",
      "weighted avg       0.74      0.75      0.74      2859\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: {:.2f}'.format(rf.score(X_validate[features], y_validate)))\n",
    "\n",
    "y_pred = rf.predict(X_validate[features])\n",
    "\n",
    "\n",
    "\n",
    "print(classification_report(y_validate, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------\n",
    "\n",
    "<h3>Decision Tree</h3>\n",
    "\n",
    "--------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_depth=7, random_state=123)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's generate a blank, new Decision Tree model\n",
    "# Be sure to set the max_depth argument\n",
    "# clf = DecisionTreeClassifier(max_depth=3, random_state=123)\n",
    "\n",
    "clf = DecisionTreeClassifier(max_depth=7, random_state=123)\n",
    "\n",
    "# Now let's train our model on the training data\n",
    "# fitting == training the model\n",
    "clf = clf.fit(X_train, y_train)\n",
    "clf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'COSA_salary_decision_tree.pdf'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualize the model so it can explain itself!\n",
    "\n",
    "dot_data = export_graphviz(clf, feature_names= X_train.columns,rounded=True, filled=True, out_file=None)\n",
    "graph = graphviz.Source(dot_data) \n",
    "\n",
    "graph.render('COSA_salary_decision_tree', view=True, format=\"pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we'll make a set of predictions using this trained model\n",
    "y_pred = clf.predict(X_train)\n",
    "\n",
    "# Estimate the probabilities for each class\n",
    "y_pred_proba = clf.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree classifier on training set: 0.77\n"
     ]
    }
   ],
   "source": [
    "# Let's evaluate the model\n",
    "print('Accuracy of Decision Tree classifier on training set: {:.2f}'\n",
    "      .format(clf.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>FEMALE</th>\n",
       "      <td>0.693308</td>\n",
       "      <td>0.622299</td>\n",
       "      <td>0.655887</td>\n",
       "      <td>2314.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MALE</th>\n",
       "      <td>0.809669</td>\n",
       "      <td>0.853731</td>\n",
       "      <td>0.831117</td>\n",
       "      <td>4355.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.773429</td>\n",
       "      <td>0.773429</td>\n",
       "      <td>0.773429</td>\n",
       "      <td>0.773429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.751488</td>\n",
       "      <td>0.738015</td>\n",
       "      <td>0.743502</td>\n",
       "      <td>6669.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.769294</td>\n",
       "      <td>0.773429</td>\n",
       "      <td>0.770316</td>\n",
       "      <td>6669.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score      support\n",
       "FEMALE         0.693308  0.622299  0.655887  2314.000000\n",
       "MALE           0.809669  0.853731  0.831117  4355.000000\n",
       "accuracy       0.773429  0.773429  0.773429     0.773429\n",
       "macro avg      0.751488  0.738015  0.743502  6669.000000\n",
       "weighted avg   0.769294  0.773429  0.770316  6669.000000"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_report = classification_report(y_train, y_pred, output_dict=True)\n",
    "pd.DataFrame(class_report).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      FEMALE       0.64      0.56      0.60       992\n",
      "        MALE       0.78      0.83      0.80      1867\n",
      "\n",
      "    accuracy                           0.74      2859\n",
      "   macro avg       0.71      0.70      0.70      2859\n",
      "weighted avg       0.73      0.74      0.73      2859\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Compare actual y values from validate to predictions based on X_validate\n",
    "print(classification_report(y_validate, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "The baseline accuracy is 65.0%\n",
      "\n",
      "\n",
      "Logistic Regression Train Accuracy --- 69.74%\n",
      "Decision Tree Train Accuracy --- 77.34%\n",
      "Random Forest Train Accuracy --- 84.81%\n",
      "KNN Accuracy Train Accuracy --- 79.94%\n",
      "\n",
      "\n",
      "Logistic Regression Validate Accuracy --- 69.67%\n",
      "Decision Tree Validate Accuracy --- 73.70%\n",
      "Random Forest Validate Accuracy --- 74.57%\n",
      "KNN Validate Accuracy --- 71.18%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "logreg_train_accuracy = logit.score(X_train[features], y_train)\n",
    "decisiontree_train_accuracy = clf.score(X_train, y_train)\n",
    "random_forest_train_accuracy = rf.score(X_train[features], y_train)\n",
    "knn_train_accuracy = knn.score(X_train[features], y_train)\n",
    "\n",
    "logreg_validate_accuracy = logit.score(X_validate[features], y_validate)\n",
    "decisiontree_validate_accuracy = clf.score(X_validate, y_validate)\n",
    "random_forest_validate_accuracy = rf.score(X_validate[features], y_validate)\n",
    "knn_validate_accuracy = knn.score(X_validate[features], y_validate)\n",
    "print('\\n')\n",
    "print(f'The baseline accuracy is {baseline_accuracy}%')\n",
    "print('\\n')\n",
    "\n",
    "print(f\"Logistic Regression Train Accuracy --- {logreg_train_accuracy:.2%}\")\n",
    "print(f\"Decision Tree Train Accuracy --- {decisiontree_train_accuracy:.2%}\")\n",
    "print(f\"Random Forest Train Accuracy --- {random_forest_train_accuracy:.2%}\")\n",
    "print(f\"KNN Accuracy Train Accuracy --- {knn_train_accuracy:.2%}\")\n",
    "print('\\n')\n",
    "print(f\"Logistic Regression Validate Accuracy --- {logreg_validate_accuracy:.2%}\")\n",
    "print(f\"Decision Tree Validate Accuracy --- {decisiontree_validate_accuracy:.2%}\")\n",
    "print(f\"Random Forest Validate Accuracy --- {random_forest_validate_accuracy:.2%}\")\n",
    "print(f\"KNN Validate Accuracy --- {knn_validate_accuracy:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy --- 75.61%\n"
     ]
    }
   ],
   "source": [
    "random_forest_test_accuracy = rf.score(X_test[features], y_test)\n",
    "print(f\"Random Forest Accuracy --- {random_forest_test_accuracy:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual_Gender</th>\n",
       "      <th>Model_Predictions</th>\n",
       "      <th>Model_Probabilities</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>REF #</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10813</th>\n",
       "      <td>FEMALE</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>0.317292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1100</th>\n",
       "      <td>MALE</td>\n",
       "      <td>MALE</td>\n",
       "      <td>0.989238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5554</th>\n",
       "      <td>MALE</td>\n",
       "      <td>MALE</td>\n",
       "      <td>0.758551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10933</th>\n",
       "      <td>FEMALE</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>0.281459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2643</th>\n",
       "      <td>MALE</td>\n",
       "      <td>MALE</td>\n",
       "      <td>0.624311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7535</th>\n",
       "      <td>MALE</td>\n",
       "      <td>MALE</td>\n",
       "      <td>0.814952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6509</th>\n",
       "      <td>FEMALE</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>0.277255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11837</th>\n",
       "      <td>MALE</td>\n",
       "      <td>MALE</td>\n",
       "      <td>0.665670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>MALE</td>\n",
       "      <td>MALE</td>\n",
       "      <td>0.955197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4991</th>\n",
       "      <td>FEMALE</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>0.387890</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2382 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Actual_Gender Model_Predictions  Model_Probabilities\n",
       "REF #                                                     \n",
       "10813        FEMALE            FEMALE             0.317292\n",
       "1100           MALE              MALE             0.989238\n",
       "5554           MALE              MALE             0.758551\n",
       "10933        FEMALE            FEMALE             0.281459\n",
       "2643           MALE              MALE             0.624311\n",
       "...             ...               ...                  ...\n",
       "7535           MALE              MALE             0.814952\n",
       "6509         FEMALE            FEMALE             0.277255\n",
       "11837          MALE              MALE             0.665670\n",
       "93             MALE              MALE             0.955197\n",
       "4991         FEMALE            FEMALE             0.387890\n",
       "\n",
       "[2382 rows x 3 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
